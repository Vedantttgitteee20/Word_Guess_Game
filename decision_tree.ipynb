{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TpBInhj86WKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498c8663-6cdf-4a18-9592-2c90cf1bbaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "xf9HglQQ6Xce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBXKyKAc3Nbx"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = np.loadtxt('/content/drive/MyDrive/dict.txt', dtype = str)\n",
        "num_words = len( words )"
      ],
      "metadata": {
        "id": "qPd26xnd7EvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_fit( words):\n",
        "\tverbose = False\n",
        "\tdt = Tree( min_leaf_size = 1, max_depth = 15 )\n",
        "\tdt.fit( words, verbose )\n",
        "\treturn dt"
      ],
      "metadata": {
        "id": "F_jXId6i9B7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tree:\n",
        "\tdef __init__( self, min_leaf_size, max_depth ):\n",
        "\t\tself.root = None\n",
        "\t\tself.words = None\n",
        "\t\tself.min_leaf_size = min_leaf_size\n",
        "\t\tself.max_depth = max_depth\n",
        "\n",
        "\tdef fit( self, words, verbose = False ):\n",
        "\t\tself.words = words\n",
        "\t\tself.root = Node( depth = 0, parent = None )\n",
        "\t\tif verbose:\n",
        "\t\t\tprint( \"root\" )\n",
        "\t\t\tprint( \"└───\", end = '' )\n",
        "\t\t# The root is trained with all the words\n",
        "\t\tself.root.fit( all_words = self.words, my_words_idx = np.arange( len( self.words ) ), min_leaf_size = self.min_leaf_size, max_depth = self.max_depth, verbose = verbose )\n",
        ""
      ],
      "metadata": {
        "id": "eGftk3v7-LI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "\t# A node stores its own depth (root = depth 0), a link to its parent\n",
        "\t# A link to all the words as well as the words that reached that node\n",
        "\t# A dictionary is used to store the children of a non-leaf node.\n",
        "\t# Each child is paired with the response that selects that child.\n",
        "\t# A node also stores the query-response history that led to that node\n",
        "\t# Note: my_words_idx only stores indices and not the words themselves\n",
        "\tdef __init__( self, depth, parent ):\n",
        "\t\tself.depth = depth\n",
        "\t\tself.parent = parent\n",
        "\t\tself.all_words = None\n",
        "\t\tself.my_words_idx = None\n",
        "\t\tself.children = {}\n",
        "\t\tself.is_leaf = True\n",
        "\t\tself.query_idx = None\n",
        "\t\tself.history = []\n",
        "\n",
        "\t# Each node must implement a get_query method that generates the\n",
        "\t# query that gets asked when we reach that node. Note that leaf nodes\n",
        "\t# also generate a query which is usually the final answer\n",
        "\tdef get_query( self ):\n",
        "\t\treturn self.query_idx\n",
        "\n",
        "\t# Each non-leaf node must implement a get_child method that takes a\n",
        "\t# response and selects one of the children based on that response\n",
        "\tdef get_child( self, response ):\n",
        "\t\t# This case should not arise if things are working properly\n",
        "\t\t# Cannot return a child if I am a leaf so return myself as a default action\n",
        "\t\tif self.is_leaf:\n",
        "\t\t\tprint( \"Why is a leaf node being asked to produce a child? Melbot should look into this!!\" )\n",
        "\t\t\tchild = self\n",
        "\t\telse:\n",
        "\t\t\t# This should ideally not happen. The node should ensure that all possibilities\n",
        "\t\t\t# are covered, e.g. by having a catch-all response. Fix the model if this happens\n",
        "\t\t\t# For now, hack things by modifying the response to one that exists in the dictionary\n",
        "\t\t\tif response not in self.children:\n",
        "\t\t\t\tprint( f\"Unknown response {response} -- need to fix the model\" )\n",
        "\t\t\t\tresponse = list(self.children.keys())[0]\n",
        "\n",
        "\t\t\tchild = self.children[ response ]\n",
        "\n",
        "\t\treturn child\n",
        "\n",
        "\tdef get_intersection( self, history ):\n",
        "\t\tlst = history[0]\n",
        "\t\tres = lst[1]\n",
        "\t\tans = \" \"\n",
        "\t\tfor li in history:\n",
        "\t\t\trespo = li[1]\n",
        "\t\t\tfor i in range(min(len(res),len(respo))):\n",
        "\t\t\t\tif res[i]=='_' and respo[i]=='_':\n",
        "\t\t\t\t\tans += \"_ \"\n",
        "\t\t\t\telif res[i]!='_' and res[i]!=\" \":\n",
        "\t\t\t\t\tans += res[i]\n",
        "\t\t\t\t\tans += \" \"\n",
        "\t\t\t\telif respo[i]!='_' and respo[i]!=\" \":\n",
        "\t\t\t\t\tans += respo[i]\n",
        "\t\t\t\t\tans += \" \"\n",
        "\t\t\tres = respo\n",
        "\t\treturn ans.split()\n",
        "\n",
        "\t# Dummy leaf action -- just return the first word\n",
        "\tdef process_leaf( self, my_words_idx, history ):\n",
        "\t\t\treturn my_words_idx[0]\n",
        "\n",
        "\tdef reveal( self, word, query ):\n",
        "\t\t# Find out the intersections between the query and the word\n",
        "\t\tmask = [ *( '_' * len( word ) ) ]\n",
        "\n",
        "\t\tfor i in range( min( len( word ), len( query ) ) ):\n",
        "\t\t\tif word[i] == query[i]:\n",
        "\t\t\t\tmask[i] = word[i]\n",
        "\n",
        "\t\treturn ' '.join( mask )\n",
        "\n",
        "\t# def indices(self, answer, all_words):\n",
        "\t# \tself.all_words = all_words\n",
        "\t# \tflag = 1\n",
        "\t# \tidc = []\n",
        "\t# \tfor index,word in enumerate(all_words):\n",
        "\t# \t\tflag=1\n",
        "\t# \t\tfor i in range(min(len(word),len(answer))):\n",
        "\t# \t\t\tif answer[i]!='_' and answer[i]!=word[i]:\n",
        "\t# \t\t\t\tflag = 0\n",
        "\t# \t\tif flag==1:\n",
        "\t# \t\t\tidc.append(index)\n",
        "\t# \treturn idc\n",
        "\n",
        "\tdef get_optimized_query( self, my_words_idx, all_words,history):\n",
        "\t\t\tself.history=history\n",
        "\t\t\tself.all_words = all_words\n",
        "\t\t\tself.my_words_idx = my_words_idx\n",
        "\t\t\t# random_idx = np.random.choice(len(all_words),500,replace=False)\n",
        "\t\t\t# random_word_pairs = [(i, all_words[i]) for i in random_idx]\n",
        "\t\t\t# ans = self.get_intersection(history)\n",
        "\t\t\t# get_optimized_ind = self.indices(ans, all_words)\n",
        "\t\t\t# print(ans)\n",
        "\t\t\t# for j in get_optimized_ind:\n",
        "\t\t\t# \tprint(all_words[j])\n",
        "\t\t\tans = self.get_intersection( history )\n",
        "\t\t\tif '_' not in ans:\n",
        "\t\t\t\tquery = ans\n",
        "\t\t\ta = {}\n",
        "\t\t\tmax = -100\n",
        "\t\t\tquery_idx = 0\n",
        "\t\t\tquery = all_words[0]\n",
        "\t\t\tfor id in my_words_idx:\n",
        "\t\t\t\tq = all_words[id]\n",
        "\t\t\t\tif q==ans and query==ans:\n",
        "\t\t\t\t\tquery_idx = id\n",
        "\t\t\t\t\tquery = q\n",
        "\t\t\t\t\tself.process_leaf(id,history)\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tfor idx in my_words_idx:\n",
        "\t\t\t\t\tmask = self.reveal( all_words[ idx ], q)\n",
        "\t\t\t\t\tif mask not in a:\n",
        "\t\t\t\t\t\ta[ mask ] = 0\n",
        "\t\t\t\t\ta[ mask ]+=1\n",
        "\n",
        "\t\t\t\tN = len(my_words_idx)\n",
        "\t\t\t\tsum = 0\n",
        "\t\t\t\tfor (rev,l) in a.items():\n",
        "\t\t\t\t\tsum+=l*np.log(l)/(N*np.log(2))\n",
        "\t\t\t\tif np.log(N)/np.log(2)-sum > max:\n",
        "\t\t\t\t\tmax = np.log(N)/np.log(2)-sum\n",
        "\t\t\t\t\tquery_idx = id\n",
        "\t\t\t\t\tquery = q\n",
        "\t\t\t\ta.clear()\n",
        "\n",
        "\t\t\treturn (query_idx,query)\n",
        "\n",
        "\n",
        "\t# Dummy node splitting action -- use a random word as query\n",
        "\t# Note that any word in the dictionary can be the query\n",
        "\tdef process_node( self, all_words, my_words_idx, history, verbose ):\n",
        "\t\t# For the root we do not ask any query -- Melbot simply gives us the length of the secret word\n",
        "\t\tif len( history ) == 0:\n",
        "\t\t\tquery_idx = -1\n",
        "\t\t\tquery = \"\"\n",
        "\t\telse:\n",
        "\t\t\t(query_idx,query) = self.get_optimized_query(my_words_idx, all_words,history)\n",
        "\n",
        "\t\tsplit_dict = {}\n",
        "\n",
        "\t\tif self.depth == 0:\n",
        "\t\t\tfor (i,word) in enumerate(all_words):\n",
        "\t\t\t\tmask =( \"_ \" * len(word) )[:-1]\n",
        "\t\t\t\tif mask not in split_dict:\n",
        "\t\t\t\t\tsplit_dict[mask] = []\n",
        "\n",
        "\t\t\t\tsplit_dict[mask].append(i)\n",
        "\t\t\treturn (query_idx, split_dict)\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tfor idx in my_words_idx:\n",
        "\t\t\t\tmask = self.reveal( all_words[ idx ], query )\n",
        "\t\t\t\tif mask not in split_dict:\n",
        "\t\t\t\t\tsplit_dict[ mask ] = []\n",
        "\n",
        "\t\t\t\tsplit_dict[ mask ].append( idx )\n",
        "\t\t\tif len( split_dict.items() ) < 2 and verbose:\n",
        "\t\t\t\tprint( \"Warning: did not make any meaningful split with this query!\" )\n",
        "\t\t\treturn ( query_idx, split_dict )\n",
        "\n",
        "\tdef fit( self, all_words, my_words_idx, min_leaf_size, max_depth, fmt_str = \"    \", verbose = False ):\n",
        "\t\tself.all_words = all_words\n",
        "\t\tself.my_words_idx = my_words_idx\n",
        "\n",
        "\t\t# If the node is too small or too deep, make it a leaf\n",
        "\t\t# In general, can also include purity considerations into account\n",
        "\t\tif len( my_words_idx ) <= min_leaf_size or self.depth >= max_depth:\n",
        "\t\t\tself.is_leaf = True\n",
        "\t\t\tself.query_idx = self.process_leaf( self.my_words_idx, self.history )\n",
        "\t\t\tif verbose:\n",
        "\t\t\t\tprint( '█' )\n",
        "\t\telse:\n",
        "\t\t\tself.is_leaf = False\n",
        "\t\t\t( self.query_idx, split_dict ) = self.process_node( self.all_words, self.my_words_idx, self.history, verbose )\n",
        "\n",
        "\t\t\tif verbose:\n",
        "\t\t\t\tprint( all_words[ self.query_idx ] )\n",
        "\n",
        "\t\t\tfor ( i, ( response, split ) ) in enumerate( split_dict.items() ):\n",
        "\t\t\t\tif verbose:\n",
        "\t\t\t\t\tif i == len( split_dict ) - 1:\n",
        "\t\t\t\t\t\tprint( fmt_str + \"└───\", end = '' )\n",
        "\t\t\t\t\t\tfmt_str += \"    \"\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tprint( fmt_str + \"├───\", end = '' )\n",
        "\t\t\t\t\t\tfmt_str += \"│   \"\n",
        "\n",
        "\t\t\t\t# Create a new child for every split\n",
        "\t\t\t\tself.children[ response ] = Node( depth = self.depth + 1, parent = self )\n",
        "\t\t\t\thistory = self.history.copy()\n",
        "\t\t\t\thistory.append( [ self.query_idx, response ] )\n",
        "\t\t\t\tself.children[ response ].history = history\n",
        "\n",
        "\t\t\t\t# Recursively train this child node\n",
        "\t\t\t\tself.children[ response ].fit( self.all_words, split, min_leaf_size, max_depth, fmt_str, verbose )"
      ],
      "metadata": {
        "id": "1VXosrWUjqrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time as tm\n",
        "import pickle\n",
        "import warnings\n",
        "import os"
      ],
      "metadata": {
        "id": "60yRuq44QF2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Merlin:\n",
        "\tdef __init__( self, query_max, words ):\n",
        "\t\tself.words = words\n",
        "\t\tself.num_words = len( words )\n",
        "\t\tself.secret = \"\"\n",
        "\t\tself.query_max = query_max\n",
        "\t\tself.arthur = None\n",
        "\t\tself.win_count = 0\n",
        "\t\tself.tot_query_count = 0\n",
        "\t\tself.rnd_query_count = 0\n",
        "\n",
        "\tdef meet( self, arthur ):\n",
        "\t\tself.arthur = arthur\n",
        "\n",
        "\tdef reset( self, secret ):\n",
        "\t\tself.secret = secret\n",
        "\t\tself.rnd_query_count = 0\n",
        "\n",
        "\t# Receive a message from Arthur\n",
        "\t# Process it and terminate the round or else message Arthur back\n",
        "\t# Arthur can set is_done to request termination of this round after this query\n",
        "\tdef msg( self, query_idx, is_done = False ):\n",
        "\n",
        "\t\t# Supplying an illegal value for query_idx is a way for Arthur to request\n",
        "\t\t# termination of this round immediately without even processing the current query\n",
        "\t\t# However, this results in query count being set to max for this round\n",
        "\t\tif query_idx < 0 or query_idx > self.num_words - 1:\n",
        "\t\t\twarnings.warn( \"Warning: Arthur has sent an illegal query -- terminating this round\", UserWarning )\n",
        "\t\t\tself.tot_query_count += self.query_max\n",
        "\t\t\treturn\n",
        "\n",
        "\t\t# Arthur has made a valid query\n",
        "\t\t# Find the guessed word and increase the query counter\n",
        "\t\tquery = self.words[ query_idx ]\n",
        "\t\tself.rnd_query_count += 1\n",
        "\t\t# Find out the intersections between the query and the secret\n",
        "\t\treveal = [ *( '_' * len( self.secret ) ) ]\n",
        "\n",
        "\t\tfor i in range( min( len( self.secret ), len( query ) ) ):\n",
        "\t\t\tif self.secret[i] == query[i]:\n",
        "\t\t\t\treveal[ i ] = self.secret[i]\n",
        "\n",
        "\t\t# The word was correctly guessed\n",
        "\t\tif '_' not in reveal:\n",
        "\t\t\tself.win_count += 1\n",
        "\t\t\tself.tot_query_count += self.rnd_query_count\n",
        "\t\t\treturn\n",
        "\t\t# print(reveal)\n",
        "\t\t# Too many queries have been made - terminate the round\n",
        "\t\tif self.rnd_query_count >= self.query_max:\n",
        "\t\t\tself.tot_query_count += self.rnd_query_count\n",
        "\t\t\treturn\n",
        "\n",
        "\t\t# If Arthur is done playing, terminate this round\n",
        "\t\tif is_done:\n",
        "\t\t\tself.tot_query_count += self.rnd_query_count\n",
        "\t\t\treturn\n",
        "\n",
        "\t\t# If none of the above happen, continue playing\n",
        "\t\tself.arthur.msg( ' '.join( reveal ) )\n",
        "\n",
        "\n",
        "\tdef reset_and_play( self, secret ):\n",
        "\t\tself.reset( secret )\n",
        "\t\tself.arthur.msg( ( \"_ \" * len( self.secret ) )[:-1] )"
      ],
      "metadata": {
        "id": "7DEVuYJ1Qn42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Arthur:\n",
        "\tdef __init__( self, model ):\n",
        "\t\tself.dt = model\n",
        "\t\tself.curr_node = self.dt.root\n",
        "\t\tself.merlin = None\n",
        "\t\tself.is_done = False\n",
        "\n",
        "\tdef meet( self, merlin ):\n",
        "\t\tself.merlin = merlin\n",
        "\n",
        "\tdef reset( self ):\n",
        "\t\tself.curr_node = self.dt.root\n",
        "\t\tself.is_done = False\n",
        "\n",
        "\tdef msg( self, response ):\n",
        "  # If we are not at a leaf, lets go to the appropriate child based on the response\n",
        "\t\tif not self.curr_node.is_leaf:\n",
        "\t\t\tself.curr_node = self.curr_node.get_child( response )\n",
        "\n",
        "\t\t# If we are at a leaf, we should reqeust Merlin to terminate the round after this query\n",
        "\t\telse:\n",
        "\t\t\tself.is_done = True\n",
        "\n",
        "\t\t# Either way, get the query to be sent to Merlin\n",
        "\t\tquery = self.curr_node.get_query()\n",
        "\t\tself.merlin.msg( query, self.is_done )"
      ],
      "metadata": {
        "id": "e5ayn528QzEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_max = 15\n",
        "n_trials = 5\n",
        "\n",
        "t_train = 0\n",
        "m_size = 0\n",
        "win = 0\n",
        "query = 0"
      ],
      "metadata": {
        "id": "ewmECvj8Q-Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range( n_trials ):\n",
        "\ttic = tm.perf_counter()\n",
        "\tmodel = my_fit( words )\n",
        "\ttoc = tm.perf_counter()\n",
        "\tt_train += toc - tic\n",
        "\n",
        "\twith open( f\"model_dump_{t}.pkl\", \"wb\" ) as outfile:\n",
        "\t\tpickle.dump( model, outfile, protocol=pickle.HIGHEST_PROTOCOL )\n",
        "\n",
        "\tm_size += os.path.getsize( f\"model_dump_{t}.pkl\" )\n",
        "\n",
        "\tmerlin = Merlin( query_max, words )\n",
        "\tarthur = Arthur( model )\n",
        "\tmerlin.meet( arthur )\n",
        "\tarthur.meet( merlin )\n",
        "\n",
        "\tfor ( i, secret ) in enumerate( words ):\n",
        "\t\tarthur.reset()\n",
        "\t\tmerlin.reset_and_play(secret)\n",
        "\n",
        "\twin += merlin.win_count / num_words\n",
        "\tquery += merlin.tot_query_count / num_words"
      ],
      "metadata": {
        "id": "h_6sbJLaQ_TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_train /= n_trials\n",
        "m_size /= n_trials\n",
        "win /= n_trials\n",
        "query /= n_trials\n",
        "\n",
        "print( t_train, m_size, win, query )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-aFttKyRC1F",
        "outputId": "7d5f0584-1236-46f8-fce5-a5e2e3fda1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.029642853399992 1050969.0 1.0 3.999225856396362\n"
          ]
        }
      ]
    }
  ]
}